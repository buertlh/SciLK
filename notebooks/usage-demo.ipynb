{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will guide you through loading and using the CHEMDNER model pack. First, some imports. Take note, that the first two lines only make any difference with a CUDA-enabled tensorflow installation, by forcing it to run in CPU-only mode. If instead you are willing to use a GPU, you should specify a GPU device number, e.g. `os.environ['CUDA_VISIBLE_DEVICES'] = '0'`. If you don't have a GPU or are using a CPU-only tensorflow version, you can remove these lines altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "from scilk.collections.chemdner import loaders\n",
    "from scilk.corpora import corpus\n",
    "from scilk.corpora.chemdner import parse_abstracts\n",
    "from scilk.util import intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to specify the paths to serealised data and load the tokeniser and the NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'chemdner-collection'  # this is the unarchived chemdner-collection.tgz file\n",
    "\n",
    "tokeniser_data = {\n",
    "    'tokeniser_weights': f'{root}/tokeniser-weights.hdf5',\n",
    "    'charmap': f'{root}/charmap.joblib'\n",
    "}\n",
    "detector_data = {\n",
    "    'embeddings': f'{root}/vectors.txt.gz',\n",
    "    'charmap': f'{root}/charmap.joblib',\n",
    "    'ner_weights': f'{root}/ner-weights.hdf5'\n",
    "}\n",
    "\n",
    "tokeniser = loaders.load_tokeniser(tokeniser_data)\n",
    "detector = loaders.load_detector(detector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the CHEMDNER corpus, but you can work with any other texts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [ab.body for ab in parse_abstracts('data/chemdner_corpus/testing.abstracts.txt')]\n",
    "tokenised = tokeniser(list(texts)[:100])  # only tokenise the first 100 texts to spare some time\n",
    "annotations = detector(tokenised)  # note! you must pass texts preprocessed by the bundled tokeniser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note, the NER model returns annotations as `Interval` objects (defined in `scilk.util.intervals`), literally representing a range within the source text corresponding to a detected named entity, since `Intervals`. Finally, we can extract these intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [intervals.extract(text, ivs) for text, ivs in zip(texts, annotations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
