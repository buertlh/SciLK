{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will guide you through loading and using the CHEMDNER model pack. First, some imports. Take note, that the first two lines only make any difference with a CUDA-enabled tensorflow installation, by forcing it to run in CPU-only mode. If instead you are willing to use a GPU, you should specify a GPU device number, e.g. `os.environ['CUDA_VISIBLE_DEVICES'] = '0'`. If you don't have a GPU or are using a CPU-only tensorflow version, you can remove these lines altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "from scilk.collections.chemdner import loaders\n",
    "from scilk.corpora import corpus\n",
    "from scilk.corpora.chemdner import parse_abstracts\n",
    "from scilk.util import intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to specify the paths to serealised data and load the tokeniser and the NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'chemdner-collection'  # this is the unarchived chemdner-collection.tgz file\n",
    "\n",
    "tokeniser_data = {\n",
    "    'tokeniser_weights': f'{root}/tokeniser-weights.hdf5',\n",
    "    'charmap': f'{root}/charmap.joblib'\n",
    "}\n",
    "detector_data = {\n",
    "    'embeddings': f'{root}/vectors.txt.gz',\n",
    "    'charmap': f'{root}/charmap.joblib',\n",
    "    'ner_weights': f'{root}/ner-weights.hdf5'\n",
    "}\n",
    "\n",
    "tokeniser = loaders.load_tokeniser(tokeniser_data)\n",
    "detector = loaders.load_detector(detector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the CHEMDNER corpus, but you can work with any other texts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [ab.body for ab in parse_abstracts('data/chemdner_corpus/testing.abstracts.txt')]\n",
    "tokenised = tokeniser(list(texts)[:100])  # only tokenise the first 100 texts to spare some time\n",
    "annotations = detector(tokenised)  # note! you must pass texts preprocessed by the bundled tokeniser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Interval(start=94, stop=113, data=['poly(vinyl', 'alcohol)']),\n",
       "  Interval(start=115, stop=118, data=PVA),\n",
       "  Interval(start=243, stop=246, data=PVA),\n",
       "  Interval(start=485, stop=488, data=PVA),\n",
       "  Interval(start=670, stop=673, data=PVA),\n",
       "  Interval(start=703, stop=708, data=thiol),\n",
       "  Interval(start=761, stop=764, data=PVA),\n",
       "  Interval(start=820, stop=823, data=PVA),\n",
       "  Interval(start=1154, stop=1157, data=PVA),\n",
       "  Interval(start=1301, stop=1304, data=PVA),\n",
       "  Interval(start=1369, stop=1372, data=PVA)],\n",
       " [Interval(start=667, stop=684, data=estrone-3-sulfate),\n",
       "  Interval(start=686, stop=691, data=E-3-S),\n",
       "  Interval(start=697, stop=713, data=['taurocholic', 'acid'])],\n",
       " [Interval(start=294, stop=295, data=C),\n",
       "  Interval(start=444, stop=452, data=tyrosine)],\n",
       " [Interval(start=42, stop=46, data=DOPC),\n",
       "  Interval(start=92, stop=103, data=octadecanol),\n",
       "  Interval(start=113, stop=120, data=Au(111)),\n",
       "  Interval(start=214, stop=225, data=octadecanol),\n",
       "  Interval(start=278, stop=289, data=octadecanol),\n",
       "  Interval(start=304, stop=310, data=BODIPY),\n",
       "  Interval(start=357, stop=368, data=octadecanol)],\n",
       " [Interval(start=338, stop=341, data=GSE),\n",
       "  Interval(start=404, stop=407, data=GSE),\n",
       "  Interval(start=648, stop=656, data=phenolic),\n",
       "  Interval(start=739, stop=751, data=['GSE', 'phenolic']),\n",
       "  Interval(start=945, stop=946, data=H)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note, the NER model returns annotations as `Interval` objects (defined in `scilk.util.intervals`), literally representing a range within the source text corresponding to a detected named entity, since `Intervals`. Finally, we can extract these intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [intervals.extract(text, ivs) for text, ivs in zip(texts, annotations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['poly(vinyl alcohol)',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'thiol',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'PVA',\n",
       "  'PVA'],\n",
       " ['estrone-3-sulfate', 'E-3-S', 'taurocholic acid'],\n",
       " ['C', 'tyrosine'],\n",
       " ['DOPC',\n",
       "  'octadecanol',\n",
       "  'Au(111)',\n",
       "  'octadecanol',\n",
       "  'octadecanol',\n",
       "  'BODIPY',\n",
       "  'octadecanol'],\n",
       " ['GSE', 'GSE', 'phenolic', 'GSE phenolic', 'H']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
